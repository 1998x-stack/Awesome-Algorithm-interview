<**Machine Learning Q and AI: 30 Essential Questions and Answers on Machine Learning and AI**>

#### PART I: NEURAL NETWORKS AND DEEP LEARNING
1. Embeddings, Latent Space, and Representations
2. Self-Supervised Learning
3. Few-Shot Learning
4. The Lottery Ticket Hypothesis
5. Reducing Overfitting with Data
6. Reducing Overfitting with Model Modifications
7. Multi-GPU Training Paradigms
8. The Success of Transformers
9. Generative AI Models
10. Sources of Randomness

#### PART II: COMPUTER VISION
11. Calculating the Number of Parameters
12. Fully Connected and Convolutional Layers
13. Large Training Sets for Vision Transformers

#### PART III: NATURAL LANGUAGE PROCESSING
14. The Distributional Hypothesis
15. Data Augmentation for Text
16. Self-Attention
17. Encoder- and Decoder-Style Transformers
18. Using and Fine-Tuning Pretrained Transformers
19. Evaluating Generative Large Language Models

#### PART IV: PRODUCTION AND DEPLOYMENT
20. Stateless and Stateful Training
21. Data-Centric AI
22. Speeding Up Inference
23. Data Distribution Shifts

#### PART V: PREDICTIVE PERFORMANCE AND MODEL EVALUATION
24. Poisson and Ordinal Regression
25. Confidence Intervals
26. Confidence Intervals vs. Conformal Predictions
27. Proper Metrics
28. The k in k-Fold Cross-Validation
29. Training and Test Set Discordance
30. Limited Labeled Data